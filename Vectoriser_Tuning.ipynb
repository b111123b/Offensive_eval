{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OffensiveEval Model Tuning\n",
    "After already using the other notebook to test out the basic capabilities of several of the most popular models, in this notebook I will start using different methods to try and increase the accuracy of the models.\n",
    "\n",
    "The first part of this will be me trying to tune the vectoriser. I will make a small pipeline to test several different variations of BoW on a naive bayes model. This is just because it has the fastest time to train and run and will lead to the quickest pipelines.\n",
    "\n",
    "I will be trying to use k-fold cross validation to verify my results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/olid-training-v2.0.tsv'\n",
    "testset = pd.read_table(path, header=None, names=['id','tweet','sub_a','sub_b','sub_c'])\n",
    "# Just gonna be using the training data to do all this testing, at least to start with.\n",
    "# Just so I can try my best to avoid overfitting of any kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset['label_a_num'] = testset.sub_a.map({'NOT':0, 'OFF':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = testset.tweet\n",
    "y = testset.label_a_num\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "classifier: SGDClassifier\n",
      "parameters:\n",
      "{'clf__alpha': (0.0001, 1e-05, 0.0002, 2e-05),\n",
      " 'clf__penalty': ('l1', 'l2', 'elasticnet'),\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
      " 'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': ('english',)}\n",
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=8)]: Done 4800 out of 4800 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 274.767s\n",
      "scoring paramater: f1\n",
      "Best score: 0.586\n",
      "Best parameters set:\n",
      "\tclf__alpha: 2e-05\n",
      "\tclf__penalty: 'l1'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__max_df: 0.9\n",
      "\tvect__min_df: 3\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier())])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0, 0.9),\n",
    "    'vect__stop_words': ('english',),\n",
    "    'vect__min_df': (2, 0.1, 3, 0.2, 4),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2),),  \n",
    "    'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1','l2'),\n",
    "#     'clf__max_iter': (100000,),\n",
    "    'clf__penalty': ('l1','l2', 'elasticnet'),\n",
    "    'clf__alpha': (0.0001,0.00001,0.0002,0.00002),\n",
    "}\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    grid_pipeline = GridSearchCV(pipe,parameters,n_jobs=8,verbose=1, scoring='f1')\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "    print(\"classifier: SGDClassifier\")\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_pipeline.fit(x_train,y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print(\"scoring paramater: f1\")\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_pipeline.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_pipeline.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_vanilla = CountVectorizer(stop_words='english',)\n",
    "vect_maxDF = CountVectorizer(stop_words='english', max_df=0.9)\n",
    "vect_minDF = CountVectorizer(stop_words='english', min_df=2)\n",
    "vect_2gram = CountVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "vect_3gram = CountVectorizer(stop_words='english', ngram_range=(1, 3))\n",
    "vect_combined = CountVectorizer(stop_words='english', ngram_range=(1, 2), min_df=2)\n",
    "vect_gridsearch1 = CountVectorizer(max_df=0.75, stop_words='english', ngram_range=(1, 1), min_df=3)\n",
    "vect_gridsearch2 = CountVectorizer(max_df=1.0, stop_words='english', ngram_range=(1, 1), min_df=4)\n",
    "vect_gridsearch3 = CountVectorizer(max_df=0.5, stop_words='english', ngram_range=(1, 2), min_df=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = [\n",
    "    vect_vanilla,\n",
    "    vect_minDF,\n",
    "    vect_2gram,\n",
    "    vect_3gram,\n",
    "    vect_combined,\n",
    "    vect_maxDF,\n",
    "    vect_gridsearch1,\n",
    "    vect_gridsearch2,\n",
    "    vect_gridsearch3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(stop_words='english')\n",
      "model score: 0.776\n",
      "CountVectorizer(min_df=2, stop_words='english')\n",
      "model score: 0.774\n",
      "CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
      "model score: 0.769\n",
      "CountVectorizer(ngram_range=(1, 3), stop_words='english')\n",
      "model score: 0.760\n",
      "CountVectorizer(min_df=2, ngram_range=(1, 2), stop_words='english')\n",
      "model score: 0.774\n",
      "CountVectorizer(max_df=0.9, stop_words='english')\n",
      "model score: 0.774\n",
      "CountVectorizer(max_df=0.75, min_df=3, stop_words='english')\n",
      "model score: 0.773\n",
      "CountVectorizer(min_df=4, stop_words='english')\n",
      "model score: 0.773\n",
      "CountVectorizer(max_df=0.5, min_df=4, ngram_range=(1, 2), stop_words='english')\n",
      "model score: 0.773\n"
     ]
    }
   ],
   "source": [
    "for vect in vectoriser:\n",
    "    pipe = Pipeline(steps=[('vectoriser', vect),\n",
    "                           ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                          ('classifier', SGDClassifier(penalty='elasticnet'))])\n",
    "    pipe.fit(x_train,y_train)\n",
    "    print(vect)\n",
    "    print(\"model score: %.3f\" % pipe.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', min_df=2, max_df=0.5)\n",
    "tf_idf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 ms ¬± 2.64 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1709,  503],\n",
       "       [ 470,  628]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dtm = vect.fit_transform(x_train)\n",
    "x_test_dtm = vect.transform(x_test)\n",
    "nb = SGDClassifier(penalty='l1', alpha=2e-05)\n",
    "obj_nb = %timeit -o nb.fit(x_train_dtm, y_train)\n",
    "y_pred_class = nb.predict(x_test_dtm)\n",
    "nb_acc = metrics.accuracy_score(y_test, y_pred_class)\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x7115 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 82989 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7060422960725076"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5552608311229"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5719489981785064"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.670945883331857"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_class, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11561          @USER We the People   Not you the poitician\n",
       "7659                    @USER Just announced on ESPN he is\n",
       "9151         @USER üòâüòçüòòYou are welcome anytime my dear.üòâüòçüòòüòò\n",
       "3953     He can shout out to me any time he wishes.... ...\n",
       "4732     @USER I have him in 2 leagues and he is probab...\n",
       "                               ...                        \n",
       "3472     @USER ‚ÄúBecause you are alone‚Äù dang Mama Chu is...\n",
       "5231     @USER You 100% believe AB would be the player ...\n",
       "571      VOTING IS NOT OPTIONAL!!! CERTAINLY NOT THIS N...\n",
       "6181     @USER So you are advocating for a 35-person de...\n",
       "4050     @USER Lol same. Mom: why don‚Äôt you do art of r...\n",
       "Name: tweet, Length: 1709, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[(y_pred_class==0) & (y_test==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@USER Lol same. Mom: why don‚Äôt you do art of real people? Me: he is a real people.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[4050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
