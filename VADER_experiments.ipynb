{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OffensiveEval VADER Experiments\n",
    "So in this notebook i will be trying to conduct some experiments with the VADER sentiment analysis tool [Github Link](https://github.com/cjhutto/vaderSentiment#demo-including-example-of-non-english-text-translations).\n",
    "\n",
    "What i'm gonna try and do is add a column to the dataframe that has the compound score from VADER. Hopefully this extra bit of sentiment analysis will help the clasifier with things like sarcasm negations and use of degree modifiers such as 'very' or using lots of punctuation e.g. 'Great!!!!'\n",
    "\n",
    "Uses of VADER taken from github README:\n",
    "\n",
    "\n",
    "examples of typical use cases for sentiment analysis, including proper handling of sentences with:\n",
    "\n",
    ">\t- typical negations (e.g., \"*not* good\")\n",
    "\t- use of contractions as negations (e.g., \"*wasn't* very good\")\n",
    "\t- conventional use of **punctuation** to signal increased sentiment intensity (e.g., \"Good!!!\")\n",
    "\t- conventional use of **word-shape** to signal emphasis (e.g., using ALL CAPS for words/phrases)\n",
    "\t- using **degree modifiers** to alter sentiment intensity (e.g., intensity *boosters* such as \"very\" and intensity *dampeners* such as \"kind of\")\n",
    "\t- understanding many **sentiment-laden slang** words (e.g., 'sux')\n",
    "\t- understanding many sentiment-laden **slang words as modifiers** such as 'uber' or 'friggin' or 'kinda'\n",
    "\t- understanding many sentiment-laden **emoticons** such as :) and :D\n",
    "\t- translating **utf-8 encoded emojis** such as üíò and üíã and üòÅ\n",
    "\t- understanding sentiment-laden **initialisms and acronyms** (for example: 'lol')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\anjum\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: requests in c:\\users\\anjum\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\anjum\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anjum\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\anjum\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\anjum\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/olid-training-v2.0.tsv'\n",
    "testset = pd.read_table(path, header=None, names=['id','tweet','sub_a','sub_b','sub_c'])\n",
    "# Just gonna be using the training data to do all this testing, at least to start with.\n",
    "# Just so I can try my best to avoid overfitting of any kind\n",
    "testset['label_a_num'] = testset.sub_a.map({'NOT':0, 'OFF':1})\n",
    "x = testset.tweet\n",
    "y = testset.label_a_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del testset['sub_b']\n",
    "del testset['sub_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_testset = testset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sub_a</th>\n",
       "      <th>label_a_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet sub_a  label_a_num\n",
       "0  86426  @USER She should ask a few native Americans wh...   OFF            1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_testset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_tweet = testset.iloc[1,].tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.201, 'neu': 0.799, 'pos': 0.0, 'compound': -0.5067}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(example_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vader_compound_score(tweet):\n",
    "    scores = analyzer.polarity_scores(tweet)\n",
    "    compound = scores['compound']\n",
    "    return compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset['vader_compound_score'] = testset['tweet'].map(get_vader_compound_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sub_a</th>\n",
       "      <th>label_a_num</th>\n",
       "      <th>vader_compound_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you‚Äôre drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.5067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13225</th>\n",
       "      <td>22965</td>\n",
       "      <td>@USER Can we all agree that Tomlins seat is he...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13226</th>\n",
       "      <td>11132</td>\n",
       "      <td>@USER when you coming to ohio?</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>87416</td>\n",
       "      <td>@USER @USER @USER @USER Liars like the Antifa ...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>56034</td>\n",
       "      <td>@USER @USER He is involved because he was ther...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>34461</td>\n",
       "      <td>@USER @USER @USER How much lonely she is and h...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13230 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet sub_a  \\\n",
       "0      86426  @USER She should ask a few native Americans wh...   OFF   \n",
       "1      90194  @USER @USER Go home you‚Äôre drunk!!! @USER #MAG...   OFF   \n",
       "2      16820  Amazon is investigating Chinese employees who ...   NOT   \n",
       "3      62688  @USER Someone should'veTaken\" this piece of sh...   OFF   \n",
       "4      43605  @USER @USER Obama wanted liberals &amp; illega...   NOT   \n",
       "...      ...                                                ...   ...   \n",
       "13225  22965  @USER Can we all agree that Tomlins seat is he...   NOT   \n",
       "13226  11132                     @USER when you coming to ohio?   NOT   \n",
       "13227  87416  @USER @USER @USER @USER Liars like the Antifa ...   OFF   \n",
       "13228  56034  @USER @USER He is involved because he was ther...   NOT   \n",
       "13229  34461  @USER @USER @USER How much lonely she is and h...   NOT   \n",
       "\n",
       "       label_a_num  vader_compound_score  \n",
       "0                1                0.0000  \n",
       "1                1               -0.5067  \n",
       "2                0                0.4767  \n",
       "3                1               -0.1779  \n",
       "4                0                0.0000  \n",
       "...            ...                   ...  \n",
       "13225            0                0.6486  \n",
       "13226            0                0.0000  \n",
       "13227            1               -0.1027  \n",
       "13228            0               -0.4003  \n",
       "13229            0                0.7574  \n",
       "\n",
       "[13230 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words='english', min_df=2, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dtm = vect.fit_transform(x_train)\n",
    "x_test_dtm = vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9930x7115 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 82989 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.concat([ df[['text']], df['vader'].apply(pd.Series) ], axis='columns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
